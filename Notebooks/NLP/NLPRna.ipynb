{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUOQ91HjSH4j9CqwSZhSIw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carloscesar182/ai_advanced_course/blob/main/Notebooks/NLP/NLPRna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "462c0YOG2lcO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# definir seed pro numpy, tensorflow e random\n",
        "# a ideia é tentar repetir o resultado se rodar esse notebook mais de uma vez em termos de performance\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)"
      ],
      "metadata": {
        "id": "387zSyei4EgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importar e visualizar os dados\n",
        "spam = pd.read_csv('spam.csv')\n",
        "spam.head()"
      ],
      "metadata": {
        "id": "zJ314SZN4eL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ver o formato\n",
        "spam.shape"
      ],
      "metadata": {
        "id": "VSVOqKfQ5E37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conferir categoria desbalanceada\n",
        "count = spam['Category'].value_counts()\n",
        "print(count)"
      ],
      "metadata": {
        "id": "65fxwvNL5KOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# balanceamento de classes\n",
        "ham_samples = spam[spam['Category'] == 'ham'].sample(n=747, random_state=42)\n",
        "spam_samples = spam[spam['Category'] == 'spam']\n",
        "\n",
        "spam = pd.concat([ham_samples, spam_samples]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "spam.shape"
      ],
      "metadata": {
        "id": "7IkiW_QW5cSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criar e aplicar o label encoder na classe\n",
        "labelencoder = LabelEncoder()\n",
        "y = labelencoder.fit_transform(spam['Category'])\n",
        "y"
      ],
      "metadata": {
        "id": "KFE2ewIG6TGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converter mensagens pro objeto numpy\n",
        "mensagens = spam['Message'].values\n",
        "\n",
        "# fazer tokenização\n",
        "token = Tokenizer(num_words=1000)\n",
        "token.fit_on_texts(mensagens)\n",
        "\n",
        "# separar treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(mensagens, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "cfjy3rd66ngo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aqui começa o PLN de fato"
      ],
      "metadata": {
        "id": "SqLwLavE7BZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# usar o metedo text to sequence pra transformar numa caracterização numérica\n",
        "X_train = token.texts_to_sequences(X_train)\n",
        "X_test = token.texts_to_sequences(X_test) # temos que aplicar tbm nos dados de teste"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ah-l0768682a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "vb_8qnRa7di7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aplicar o pad sequence pra transformar o nosso texto em tamanho padrão\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=500)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=500)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)"
      ],
      "metadata": {
        "id": "dNRTTiA370D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criar a rede neural\n",
        "# camada de entrada\n",
        "input_layer = Input(shape=(500,))\n",
        "\n",
        "# camada de embedding\n",
        "embedding_layer = Embedding(input_dim=token.num_words + 1, output_dim=50)(input_layer)\n",
        "\n",
        "# camada de achatamento\n",
        "flatten_layer = Flatten()(embedding_layer) # achata a camada de entrada\n",
        "\n",
        "# camada densa\n",
        "dense_layer = Dense(units=10, activation='relu')(flatten_layer)\n",
        "\n",
        "# camada de dropout pra reduzir overfitting\n",
        "dropout_layer = Dropout(0.1)(dense_layer)\n",
        "\n",
        "# camada de saída\n",
        "output_layer = Dense(units=1, activation='sigmoid')(dropout_layer)\n",
        "\n",
        "# criar o modelo\n",
        "modelo = Model(inputs=input_layer, outputs=output_layer)"
      ],
      "metadata": {
        "id": "TCdvIDgM8CfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compilar o modelo\n",
        "modelo.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "johfXmw89X3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# treinar o modelo\n",
        "modelo.fit(X_train, y_train, epochs=20, batch_size=10, verbose=True, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "W5C52sAq9hJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gerar as metricas com os dados de teste\n",
        "loss, accuracy = modelo.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "b1uspGjL-qnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fazer uma nova previsão para os dados de teste\n",
        "nova_previsao = modelo.predict(X_test)\n",
        "print(nova_previsao[2:5])"
      ],
      "metadata": {
        "id": "RwfGovjo_i-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformar as previsões em valores booleanos\n",
        "previsoes_bool = (nova_previsao > 0.5)\n",
        "print(previsoes_bool[2:5])"
      ],
      "metadata": {
        "id": "NRNAC_fB_7mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gerar uma matriz de confusão\n",
        "matriz_confusao = confusion_matrix(y_test, previsoes_bool)\n",
        "print(matriz_confusao)"
      ],
      "metadata": {
        "id": "9pSxtnyPAH7F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}