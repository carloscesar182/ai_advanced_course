{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPE3KfAtbtgUCJgMY+DTCMC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carloscesar182/ai_advanced_course/blob/main/Notebooks/MLAdvTechniques/BestCluster.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsKkCT_yCoG1"
      },
      "outputs": [],
      "source": [
        "# pegar as 3 principais metricas e comparar (kmeans, dbscan e agglomerative)\n",
        "# também identificar o número ideal de clusters\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criar uma função de comparar algoritmos\n",
        "def compare_algorithms(X, max_clusters): # X passa os dados, max_cluster passa os clusters. Vai de 2 até max\n",
        "    results = [] # lista para armazenar os resultados que a função vai processar\n",
        "    cluster_range = range(2, max_clusters +1)\n",
        "\n",
        "    # k-means\n",
        "    for n_clusters in cluster_range:\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init='auto')\n",
        "        clusters = kmeans.fit_predict(X) # chama método fit passando os dados de X\n",
        "        silhouette_avg = silhouette_score(X, clusters) # procura o silhoutte score dos dados\n",
        "        results.append(('Kmeans', n_clusters, silhouette_avg)) # adiciona o resultado na lista que criamos (results)\n",
        "\n",
        "    # agglomerative\n",
        "    for n_clusters in cluster_range:\n",
        "        agglomerative = AgglomerativeClustering(n_clusters=n_clusters) # chama o método\n",
        "        clusters = agglomerative.fit_predict(X) # chama o fit com os mesmos dados e armazena na variável clusters\n",
        "        silhouette_avg = silhouette_score(X, clusters) # armazena o silhouette score na variável silhouette_avg\n",
        "        results.append(('AgglomerativeClustering', n_clusters, silhouette_avg)) # adiciona o resultado na lista results[]\n",
        "\n",
        "    # dbscan\n",
        "    # ignora a variavel n_clusters e adiciona os dados numa nova variável eps_values pq o dbscan define o num cluster automaticamente\n",
        "    eps_values = np.arange(0.1, 0.9, 0.1) # np_arange vai de 0.1 a 0.9 aumentando de 1 em 1\n",
        "    for eps in eps_values:\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=5)\n",
        "        clusters = dbscan.fit_predict(X) # chama o fit passando X pra variável clusters\n",
        "        # como dbscan não tem a obrigação de gerar clusters, é provável que no intervalo ele gere valor sem cluster nenhum\n",
        "        if len(set(clusters)) > 1: # se comprimento maior que 1:\n",
        "            silhouette_avg = silhouette_score(X, clusters)\n",
        "            results.append(('DBSCAN', eps, silhouette_avg))\n",
        "\n",
        "    return results # results pq é a variável que está acumulando os resultados das métricas"
      ],
      "metadata": {
        "id": "RTqUPFtLErma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carregar o dataset\n",
        "iris = datasets.load_iris()\n",
        "scaler = StandardScaler()\n",
        "scaler_data = scaler.fit_transform(iris.data)\n",
        "\n",
        "# chamar a função que criamos acima pra retornar uma lista com os resultados\n",
        "results = compare_algorithms(scaler_data, 10)\n",
        "df = pd.DataFrame(results, columns=['Agrupador', 'Clusters', 'Score'])\n",
        "print(df)"
      ],
      "metadata": {
        "id": "2BKo75RuJokg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtrar o índice onde a coluna score é maior\n",
        "max_score_index = df['Score'].idxmax()\n",
        "print(df.loc[max_score_index])"
      ],
      "metadata": {
        "id": "f3zE76k4J1Un"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}