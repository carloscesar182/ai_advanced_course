{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWFn9qQkGb8Pdar5v4jnYx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carloscesar182/ai_advanced_course/blob/main/Notebooks/LLMsGenAI/TextGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xg0IPQYILSh",
        "outputId": "ac24741c-5da6-48c7-f84f-f189cc2009d9",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "ktyJZ3Y0JTRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criar um objeto do tipo pipeline pra passar a tarefa de geração de texto e o modelo de geração de texto\n",
        "gerador = pipeline(\"text-generation\", model=\"pierreguillou/gpt2-small-portuguese\")\n",
        "\n",
        "# chamar o método gerador passando um texto, max_lenght e um parametro do_sample\n",
        "# text = \"Em sentido estrito, ciência refere-se ao sistema de adquirir conhecimento baseado no método científico.\"\n",
        "text = \"Um transformer é um grande modelo de linguagem natural.\"\n",
        "resultado = gerador(text, max_length=100, do_sample=True) # do_sample verdadeiro pode criar palavras aleatória, e tenho chance maior do texto ser variado\n",
        "print(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-T5qXe5JXCB",
        "outputId": "ac8801ea-ea1e-4f8b-dbd4-d0167304c744",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'Um transformer é um grande modelo de linguagem natural. A partir de uma transformer de uma linguagem natural, o sistema de símbolos é reduzido e a representação de símbolos é reduzida.\\n\\nA Transformer é um paradigma de programação para linguagens de programação. É um paradigma onde uma linguagem de programação é construída com o mesmo algoritmo de um sistema de linguagens de programação.\\n\\nA Transformer é uma linguagem de programação que não é uma linguagem de programação, mas sim uma linguagem de programação que utiliza uma linguagem de programação em vez de uma linguagem de programação de tempo real. A linguagem de programação de tempo real é construída usando o mesmo algoritmo de tempo real. A linguagem de programação de tempo real também é uma linguagem de programação que usa um algoritmo de tempo real para simular certas condições, como a previsão de futuros eventos.\\n\\nA linguagem de programação de tempo real é construída usando o mesmo algoritmo de tempo real.\\n\\nO exemplo da Transformer é uma linguagem de programação que não é uma linguagem de programação. O exemplo da Transformer é uma linguagem de programação que é construída usando o mesmo algoritmo de tempo real.\\n\\nA Transformer também é uma linguagem de programação que não é uma linguagem de programação. O exemplo da Transformer é uma linguagem de programação que é construída usando o mesmo algoritmo de tempo real.\\n\\nO exemplo'}]\n"
          ]
        }
      ]
    }
  ]
}