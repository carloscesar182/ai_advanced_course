{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvQ09lGW3lsXNoK39eHPPV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carloscesar182/ai_advanced_course/blob/main/Notebooks/RNA/DeteccaoObjetos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTI3i3tinJTJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criar 2 variaveis: caminho do modelo e caminho dos pesos\n",
        "MODEL_CONFIG = \"MobileNetSSD_deploy.prototxt\"\n",
        "MODEL_WEIGHTS = \"MobileNetSSD_deploy.caffemodel\"\n",
        "\n",
        "# criar uma lista com as classes\n",
        "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\",\n",
        "          \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\",\n",
        "           \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]"
      ],
      "metadata": {
        "id": "tcT9k4LQoFOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carregar o modelo\n",
        "net = cv2.dnn.readNetFromCaffe(MODEL_CONFIG, MODEL_WEIGHTS)"
      ],
      "metadata": {
        "id": "gBt7oKR_pbOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criar uma função que processa a detecção do objeto\n",
        "# ela vai receber o caminho do video, carregar o video, rodar o video até acabar ou detectar o objeto\n",
        "def detect_person_in_video(video_path):\n",
        "  cap = cv2.VideoCapture(video_path) # carrega o video\n",
        "  frame_count = 0 # variável de controle pra contar os frames\n",
        "  while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      print(\"Fim do video ou erro de leitura\")\n",
        "      break\n",
        "    frame_count += 1\n",
        "\n",
        "    # pegar largura e altura do objeto\n",
        "    (h, w) = frame.shape[:2]\n",
        "\n",
        "    # preprocessar o frame\n",
        "    # frame + boas práticas de normalização + tamanho + valor a ser subtraído\n",
        "    blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), 127.5)\n",
        "\n",
        "    # processar na rede neural\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # o objeto detection é uma lista com 4 valores\n",
        "    # batch 0, indice = id da classe, confiança, coordenadas\n",
        "    detection = net.forward() # faz a deteção de objetos\n",
        "    for i in range(detection.shape[2]): # na posição 2 estão as detecções\n",
        "      confidence = detection[0, 0, i, 2] # pega a confiança da detecção\n",
        "      if confidence > 0.9: # se a confiança for maior que 0.9 (bem alta)\n",
        "        idx = int(detection[0, 0, i, 1])\n",
        "        if CLASSES[idx] == \"person\": # se for pessoa\n",
        "          # pegar as coordenadas da caixa onde detectou o objeto\n",
        "          box = detection[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "          (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "          # desenhar a caixa com label e retangulo\n",
        "          label = f\"{CLASSES[idx]}: {confidence * 100:.2f}%\"\n",
        "          cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
        "          # desenhar o texto\n",
        "          cv2.putText(frame, label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "          print(f\"Pessoa detectada no frame {frame_count}\")\n",
        "          # mostrar o frame\n",
        "          cv2_imshow(frame)\n",
        "          detected_frame_path = f\"detected_frame_{frame_count}.jpg\"\n",
        "          cv2.imwrite(detected_frame_path, frame)\n",
        "          print(f\"Frame salvo em: {detected_frame_path}\")\n",
        "\n",
        "          # liberar o objeto\n",
        "          cap.release()\n",
        "          return \"Pessoa detectada no video\"\n",
        "  cap.release()\n",
        "  return \"Nenhuma pessoa detectada no video\""
      ],
      "metadata": {
        "id": "gvucDp8lpgmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(detect_person_in_video(\"nopeople.mp4\"))"
      ],
      "metadata": {
        "id": "vlwpl1W2_YP3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}