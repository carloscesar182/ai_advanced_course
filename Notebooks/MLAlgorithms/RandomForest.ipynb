{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6joMzn4reAQowdqJvmgFF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carloscesar182/ai_advanced_course/blob/main/Notebooks/MLAlgorithms/RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRORiXZugF1j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # famosa biblioteca de manipulação de dados tabulários no python\n",
        "import numpy as np # para tratar dados em forma de vetores e matrizes, muito usada para IA\n",
        "import matplotlib.pyplot as plt # usado para visualização de dados\n",
        "\n",
        "# sklearn é amplamente utilizada na área de dados\n",
        "from sklearn.model_selection import train_test_split # train_test_split é usada pra dividir os dados em conjunto de treino e teste\n",
        "from sklearn.ensemble import RandomForestClassifier # biblioteca pra criar nosso modelo de random forest\n",
        "from sklearn.preprocessing import LabelEncoder # pra codificar dados categóricos em dados numéricos para que a biblioteca seja capaz de compreender e processar\n",
        "from sklearn.tree import plot_tree # para gerar o objeto\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report # métricas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importando os dados\n",
        "base = pd.read_csv(\"insurance.csv\", keep_default_na=False) # parametro keep_default_na permite escolher se mantém ou não os valores nulos padrão da base\n",
        "base.head()"
      ],
      "metadata": {
        "id": "E9WEXj-ug4Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropar coluna unnamed\n",
        "base = base.drop(columns=[\"Unnamed: 0\"])\n",
        "base.head()"
      ],
      "metadata": {
        "id": "b7s-w9Pgg-w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definir as variáveis\n",
        "y = base.iloc[:,7].values # variável dependente\n",
        "X = base.drop(base.columns[7], axis=1).values # variável independente\n",
        "X"
      ],
      "metadata": {
        "id": "van8t0EihFTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformar variáveis categóricas em numéricas\n",
        "# laço pra detectar apenas os objetos que são categóricos, que no pandas é o tipo object e transformar só eles\n",
        "labelencoder = LabelEncoder()\n",
        "for i in range(X.shape[1]): # percorre todas as colunas\n",
        "  if X[:,i].dtype == 'object': # verifica se as colunas do laço são do tipo object\n",
        "    X[:,i] = labelencoder.fit_transform(X[:,i]) # se forem, pega o labelencoder da coluna atual, transforma e coloca no mesmo objeto da coluna atual. Isso vai substituindo as colunas pela mesma informação codificada"
      ],
      "metadata": {
        "id": "dLumm8pEhI7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dividir os dados em treino e teste\n",
        "# precisamos ter 4 variáveis pra treino e teste. Independente de treino e teste e dependente de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12) # o test_size = 0.3 indica que 30% das linhas do CSV serão pra teste. Random_state garante que toda vez que rode, tenha o mesmo resultado"
      ],
      "metadata": {
        "id": "BaoZoEKGhNpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criar o modelo\n",
        "# o parametro n_estimators é quantas árvores de decisão vão ser induzidas\n",
        "modelo = RandomForestClassifier(random_state=1, max_depth=20, max_leaf_nodes=12, n_estimators=500)\n",
        "modelo.fit(X_train, y_train) # treina o modelo"
      ],
      "metadata": {
        "id": "tGRGNH04hT_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# usar bibliotecas de impressão\n",
        "tree_index = 499\n",
        "tree_to_visualize = modelo.estimators_[tree_index]\n",
        "plt.figure(figsize=(20,20))\n",
        "plot_tree(tree_to_visualize, feature_names=base.columns[:-1], filled=True, class_names=True, rounded=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FhVc2FEHh_O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes = modelo.predict(X_test)\n",
        "previsoes"
      ],
      "metadata": {
        "id": "RdeYFm3CjLTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metricas\n",
        "accuracy = accuracy_score(y_test, previsoes) # calcula o percentual de acerto comparando os dados do que aconteceu com o que foi previsto\n",
        "precision = precision_score(y_test, previsoes, average='weighted') # vai considerar as classes de forma ponderada\n",
        "recall = recall_score(y_test, previsoes, average='weighted')\n",
        "f1 = f1_score(y_test, previsoes, average='weighted')\n",
        "print(f'Acurácia: {accuracy:.2f}')\n",
        "print(f'Precisão: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1-score: {f1:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKQU8wU9jQdO",
        "outputId": "3498df78-3ff3-4fe1-94e1-c548be8c908d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.93\n",
            "Precisão: 0.93\n",
            "Recall: 0.93\n",
            "F1-score: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gerar o classification report\n",
        "report = classification_report(y_test, previsoes)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "lOF58baFjXIu",
        "outputId": "ee7e60dc-a2ba-441c-e29b-0a827f8b55ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Mild       0.88      0.61      0.72       570\n",
            "    Moderate       0.76      0.69      0.72       488\n",
            "        None       0.96      1.00      0.98      4253\n",
            "      Severe       0.87      0.93      0.90       689\n",
            "\n",
            "    accuracy                           0.93      6000\n",
            "   macro avg       0.87      0.81      0.83      6000\n",
            "weighted avg       0.93      0.93      0.93      6000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}