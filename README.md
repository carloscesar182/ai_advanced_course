# ğŸ“Š PrevisÃ£o de Renda com Machine Learning â€“ Adult Income Dataset

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![Status](https://img.shields.io/badge/status-completed-success.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Contributions](https://img.shields.io/badge/contributions-welcome-orange.svg)

Este projeto tem como objetivo **prever a faixa de renda de indivÃ­duos** a partir de variÃ¡veis socioeconÃ´micas (idade, escolaridade, ocupaÃ§Ã£o, etc.) utilizando diferentes algoritmos de *Machine Learning*.  
O dataset utilizado Ã© o **Adult Income (Census Income)**, amplamente empregado em competiÃ§Ãµes e benchmarks de classificaÃ§Ã£o.

## Principais pontos
- ğŸ“‚ Estrutura organizada em `data/`, `notebooks/` e `outputs/`
- ğŸ§¹ PrÃ©-processamento de dados com `pandas` e `scikit-learn`
- âš¡ Modelos treinados: *Logistic Regression, Random Forest, XGBoost e H2O AutoML*
- ğŸ“ˆ MÃ©tricas avaliadas: *Accuracy, Precision, Recall, F1-score, AUC*
- ğŸ” InterpretaÃ§Ã£o de modelos com `SHAP`

## ğŸ“‚ Estrutura do RepositÃ³rio
```kotlin
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ validation.csv
â”‚   â””â”€â”€ test.csv
â”œâ”€â”€ notebooks/ ou scripts/
â”‚   â””â”€â”€ ProjetoFinal.ipynb
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ figures/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ LICENSE
```

## âš™ï¸ Tecnologias Utilizadas
- **Python 3.10+**
- **Pandas / NumPy** â€“ manipulaÃ§Ã£o de dados
- **Matplotlib / Seaborn** â€“ visualizaÃ§Ã£o
- **Scikit-learn** â€“ prÃ©-processamento, modelos e mÃ©tricas
- **H2O AutoML 2.0** â€“ geraÃ§Ã£o automÃ¡tica de modelos
- **XGBoost** â€“ modelo baseado em boosting
- **SHAP** â€“ interpretabilidade (XAI)

## ğŸ” Metodologia

### 1. PrÃ©-processamento
- **Tratamento de valores ausentes** (`?` â†’ `Not-informed`)
- **AnÃ¡lise e manutenÃ§Ã£o de outliers**
- **CodificaÃ§Ã£o de variÃ¡veis categÃ³ricas** com `LabelEncoder`
- **NormalizaÃ§Ã£o dos dados** com `StandardScaler`

### 2. Modelagem
- **AutoML (H2O)** para ranking inicial de modelos
- **Modelos manuais testados:**
  - Gradient Boosting (Scikit-learn)
  - Random Forest
  - Naive Bayes

### 3. AvaliaÃ§Ã£o
- MÃ©tricas utilizadas:
  - **F1-Score** (principal)
  - AcurÃ¡cia
  - PrecisÃ£o
  - Recall
- Matrizes de confusÃ£o para anÃ¡lise de erros

### 4. Interpretabilidade
- **SHAP** para anÃ¡lise global (importÃ¢ncia das variÃ¡veis) e local (explicaÃ§Ã£o de uma prediÃ§Ã£o especÃ­fica).

## ğŸ“Š Resultados

### Ranking final dos modelos
| Ranking | Modelo                                | F1-Score |
|---------|---------------------------------------|----------|
| ğŸ¥‡ 1Âº   | Gradient Boosting (manual)            | **0.73** |
| 2Âº      | XGBoost (AutoML)                      | 0.70     |
| 3Âº      | Extra Trees (AutoML)                  | 0.70     |
| 4Âº      | Random Forest                         | 0.69     |
| 5Âº      | Gradient Boosting Annealing (AutoML)  | 0.68     |
| 6Âº      | Naive Bayes                           | 0.45     |

### MÃ©tricas finais do melhor modelo (Gradient Boosting â€“ Teste)
- **F1-Score:** 0.73  
- **AcurÃ¡cia:** 0.88  
- **PrecisÃ£o:** 0.79  
- **Recall:** 0.68  

O modelo alcanÃ§ou **bom equilÃ­brio entre precisÃ£o e recall**, com destaque para evitar falsos positivos (precisÃ£o alta).

## ğŸ§  Interpretabilidade (XAI)

O **SHAP** foi utilizado para:
- **AnÃ¡lise global**: identificar quais variÃ¡veis mais influenciam a prediÃ§Ã£o (ex.: horas trabalhadas, nÃ­vel de educaÃ§Ã£o, capital gain/loss).  
- **AnÃ¡lise local**: explicar as decisÃµes do modelo para casos especÃ­ficos.

Exemplo de visualizaÃ§Ãµes:
- `shap.summary_plot` â€“ importÃ¢ncia das features  
- `shap.force_plot` â€“ explicaÃ§Ã£o de uma prediÃ§Ã£o individual  

## ğŸš€ Como Executar o Projeto

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/carloscesar182/ai_advanced_course.git
   cd ai_advanced_course

2. Crie o ambiente virtual e instale as dependÃªncias:
   ```bash
   python -m venv venv
   source venv/bin/activate   # Linux/Mac
   venv\Scripts\activate      # Windows

   pip install -r requirements.txt

3. Execute o notebook:
   ```bash
   jupyter notebook ProjetoFinal.ipynb

## ğŸ“Œ PrÃ³ximos Passos

- Testar tÃ©cnicas de balanceamento de classes (ex.: SMOTE)
- Explorar diferentes codificaÃ§Ãµes categÃ³ricas (OneHot, Target Encoding)
- Pipeline completo com CI/CD ou DockerizaÃ§Ã£o
- Comparar interpretabilidade com outras tÃ©cnicas (ex.: LIME)

---

## ğŸ“œ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Consulte o arquivo [LICENSE](https://github.com/carloscesar182/ai_advanced_course/blob/main/LICENSE) para mais detalhes.

## âœ‰ï¸ Contato
Autor: Carlos Ferreira

LinkedIn: [https://www.linkedin.com/in/carloscferreira/](https://www.linkedin.com/in/carloscferreira/)

E-mail: [carloscesar182@gmail.com](mailto:carloscesar182@gmail.com)
